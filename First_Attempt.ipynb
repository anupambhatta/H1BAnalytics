{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Project_BigData\")\n",
    "sc = SparkContext.getOrCreate(conf = conf)\n",
    "sqlcon = SQLContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pat1 = re.compile(r'\"([a-xA-Z0-9. ,]+), ([a-xA-Z0-9. ,]+)\"')\n",
    "pat2 = re.compile(r'\"([,]+)\"')\n",
    "keep = ['CASE_STATUS','EMPLOYER_NAME','EMPLOYER_STATE',\\\n",
    "        'AGENT_REPRESENTING_EMPLOYER','JOB_TITLE','SOC_NAME','NAICS_CODE','TOTAL_WORKERS',\\\n",
    "        'NEW_EMPLOYMENT','CONTINUED_EMPLOYMENT','CHANGE_PREVIOUS_EMPLOYMENT',\\\n",
    "        'NEW_CONCURRENT_EMPLOYMENT','CHANGE_EMPLOYER','AMENDED_PETITION','FULL_TIME_POSITION',\\\n",
    "        'PREVAILING_WAGE','H1B_DEPENDENT','SUPPORT_H1B','WORKSITE_STATE']\n",
    "#We need to decide how to use the date 'CASE_SUBMITTED', add back to the list above once decided.\n",
    "categorical = {\"CASE_STATUS\":\"CASE_STATUS_C\", \"EMPLOYER_NAME\":\"EMPLOYER_NAME_C\",\\\n",
    "              \"EMPLOYER_STATE\":\"EMPLOYER_STATE_C\",\"AGENT_REPRESENTING_EMPLOYER\":\"AGENT_REPRESENTING_EMPLOYER_C\",\\\n",
    "              \"JOB_TITLE\":\"JOB_TITLE_C\",\"SOC_NAME\":\"SOC_NAME_C\",\"NAICS_CODE\":\"NAICS_CODE_C\",\\\n",
    "              \"FULL_TIME_POSITION\":\"FULL_TIME_POSITION_C\",\"H1B_DEPENDENT\":\"H1B_DEPENDENT_C\",\\\n",
    "              \"WORKSITE_STATE\":\"WORKSITE_STATE_C\",\"SUPPORT_H1B\":\"SUPPORT_H1B_C\"}\n",
    "target = [\"CASE_STATUS_C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replaceCommaWithinQuotes(line):\n",
    "    '''\n",
    "    Remove commas within quotes with some words, recursion makes sure we reomve all such commas\n",
    "    '''\n",
    "    if len(pat1.findall(line)) == 0:\n",
    "        return line\n",
    "    line = pat1.sub( r'\"\\1 \\2\"', line )\n",
    "    return replaceCommaWithinQuotes(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yearlyWage(data_dict):\n",
    "    '''\n",
    "    Converts the prevailing wage to yearly.\n",
    "    '''\n",
    "    if data_dict['PW_UNIT_OF_PAY'] == 'Hour':\n",
    "        data_dict['PREVAILING_WAGE'] = data_dict['PREVAILING_WAGE']*40*52 #40 hrs/week,52 weeks/yr\n",
    "    if data_dict['PW_UNIT_OF_PAY'] == 'Week':\n",
    "        data_dict['PREVAILING_WAGE'] = data_dict['PREVAILING_WAGE']*52    #52 weeks/yr\n",
    "    if data_dict['PW_UNIT_OF_PAY'] == 'Bi-Weekly':\n",
    "        data_dict['PREVAILING_WAGE'] = data_dict['PREVAILING_WAGE']*26    #52 weeks/yr,hence 26 bi-weeks \n",
    "    if data_dict['PW_UNIT_OF_PAY'] == 'Month':\n",
    "        data_dict['PREVAILING_WAGE'] = data_dict['PREVAILING_WAGE']*12    #12 months/yr\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createRow(line, headers):\n",
    "    '''\n",
    "    Returns a dictionary with headers as key and their values as the values\n",
    "    '''\n",
    "    data_dict = {}\n",
    "    #Replace comma, within words between two quotes, with blank\n",
    "    line = replaceCommaWithinQuotes(line) #This line may still have just comma within quotes-\",\"\n",
    "    #line = pat2.sub(r'\"\"', line) - something weird is happening because of this line\n",
    "\n",
    "    data_list = line.split(\",\")\n",
    "    j = 0 #another index\n",
    "    for i in range(len(headers)):\n",
    "        if data_list[j] == '\"': #In case we encounter a \" we avoid it and move ahead.\n",
    "            j = j+1\n",
    "        if headers[i] == \"\":\n",
    "            data_dict[\"S_NO\"] = int(data_list[j])\n",
    "        else:\n",
    "            data_dict[headers[i]] = data_list[j]\n",
    "        j = j+1\n",
    "    #We make the prevailing wage yearly\n",
    "    data_dict = yearlyWage(data_dict)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToCategorical(columns, dataframe):\n",
    "    '''\n",
    "    Converts each column in dataframe to its corresponding Cateforical column.\n",
    "    columns is a dict representing the column as key and new colmn as value.\n",
    "    '''\n",
    "    for column in columns:\n",
    "        indexer = StringIndexer(inputCol=column, outputCol=columns[column])\n",
    "        dataframe = indexer.fit(dataframe).transform(dataframe)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1b_data = sc.textFile(\\\n",
    "           \"hdfs://quickstart.cloudera:8020/user/cloudera/Project/H-1B_Disclosure_Data_FY17.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract headers from the data.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers_string = h1b_data.take(1)[0]\n",
    "headers = headers_string.split(\",\")\n",
    "h1b_data = h1b_data.filter(lambda x: x != headers_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the map and then dataframe from the map using sql context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h1_data_map = h1b_data.map(lambda x: Row(**createRow(x, headers)))\n",
    "h1b_data_frame = sqlcon.createDataFrame(h1_data_map).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Data based on visa type, we need only H1B visas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1b_data_frame = h1b_data_frame.where(h1b_data_frame['VISA_CLASS'] == 'H-1B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a small subset and convert to pandas just to show the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGENT_ATTORNEY_CITY</th>\n",
       "      <th>AGENT_ATTORNEY_NAME</th>\n",
       "      <th>AGENT_ATTORNEY_STATE</th>\n",
       "      <th>AGENT_REPRESENTING_EMPLOYER</th>\n",
       "      <th>AMENDED_PETITION</th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>CASE_SUBMITTED</th>\n",
       "      <th>CHANGE_EMPLOYER</th>\n",
       "      <th>CHANGE_PREVIOUS_EMPLOYMENT</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_WORKERS</th>\n",
       "      <th>VISA_CLASS</th>\n",
       "      <th>WAGE_RATE_OF_PAY_FROM</th>\n",
       "      <th>WAGE_RATE_OF_PAY_TO</th>\n",
       "      <th>WAGE_UNIT_OF_PAY</th>\n",
       "      <th>WILLFUL_VIOLATOR</th>\n",
       "      <th>WORKSITE_CITY</th>\n",
       "      <th>WORKSITE_COUNTY</th>\n",
       "      <th>WORKSITE_POSTAL_CODE</th>\n",
       "      <th>WORKSITE_STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>\"ELLSWORTH CHAD\"</td>\n",
       "      <td>NY</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>I-200-16055-173457</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>2016-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>H-1B</td>\n",
       "      <td>65811.0</td>\n",
       "      <td>67320.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>N</td>\n",
       "      <td>RIVERWOODS</td>\n",
       "      <td>LAKE</td>\n",
       "      <td>60015</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>\"ELLSWORTH CHAD\"</td>\n",
       "      <td>NY</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>I-200-16064-557834</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>H-1B</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>57200.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>N</td>\n",
       "      <td>RIVERWOODS</td>\n",
       "      <td>LAKE</td>\n",
       "      <td>60015</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>\"BURKE KAREN\"</td>\n",
       "      <td>DC</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>I-200-16063-996093</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>2016-03-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>H-1B</td>\n",
       "      <td>77000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>N</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td></td>\n",
       "      <td>20007</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>\"</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>I-200-16272-196340</td>\n",
       "      <td>WITHDRAWN</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>H-1B</td>\n",
       "      <td>102000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>N</td>\n",
       "      <td>JERSEY CITY</td>\n",
       "      <td>HUDSON</td>\n",
       "      <td>07302</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATLANTA</td>\n",
       "      <td>\"SCOFIELD EILEEN\"</td>\n",
       "      <td>GA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>I-200-15053-636744</td>\n",
       "      <td>CERTIFIED-WITHDRAWN</td>\n",
       "      <td>2015-02-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>H-1B</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>N</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>10036</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  AGENT_ATTORNEY_CITY AGENT_ATTORNEY_NAME AGENT_ATTORNEY_STATE  \\\n",
       "0            NEW YORK    \"ELLSWORTH CHAD\"                   NY   \n",
       "1            NEW YORK    \"ELLSWORTH CHAD\"                   NY   \n",
       "2          WASHINGTON       \"BURKE KAREN\"                   DC   \n",
       "3                                       \"                        \n",
       "4             ATLANTA   \"SCOFIELD EILEEN\"                   GA   \n",
       "\n",
       "  AGENT_REPRESENTING_EMPLOYER AMENDED_PETITION         CASE_NUMBER  \\\n",
       "0                           Y                0  I-200-16055-173457   \n",
       "1                           Y                0  I-200-16064-557834   \n",
       "2                           Y                0  I-200-16063-996093   \n",
       "3                           N                0  I-200-16272-196340   \n",
       "4                           Y                0  I-200-15053-636744   \n",
       "\n",
       "           CASE_STATUS CASE_SUBMITTED CHANGE_EMPLOYER  \\\n",
       "0  CERTIFIED-WITHDRAWN     2016-02-24               0   \n",
       "1  CERTIFIED-WITHDRAWN     2016-03-04               0   \n",
       "2  CERTIFIED-WITHDRAWN     2016-03-10               0   \n",
       "3            WITHDRAWN     2016-09-28               0   \n",
       "4  CERTIFIED-WITHDRAWN     2015-02-22               1   \n",
       "\n",
       "  CHANGE_PREVIOUS_EMPLOYMENT      ...       TOTAL_WORKERS VISA_CLASS  \\\n",
       "0                          0      ...                   1       H-1B   \n",
       "1                          0      ...                   1       H-1B   \n",
       "2                          0      ...                   2       H-1B   \n",
       "3                          0      ...                   1       H-1B   \n",
       "4                          0      ...                   1       H-1B   \n",
       "\n",
       "  WAGE_RATE_OF_PAY_FROM WAGE_RATE_OF_PAY_TO WAGE_UNIT_OF_PAY WILLFUL_VIOLATOR  \\\n",
       "0               65811.0             67320.0             Year                N   \n",
       "1               53000.0             57200.0             Year                N   \n",
       "2               77000.0                 0.0             Year                N   \n",
       "3              102000.0                 0.0             Year                N   \n",
       "4              132500.0                 0.0             Year                N   \n",
       "\n",
       "  WORKSITE_CITY WORKSITE_COUNTY WORKSITE_POSTAL_CODE WORKSITE_STATE  \n",
       "0    RIVERWOODS            LAKE                60015             IL  \n",
       "1    RIVERWOODS            LAKE                60015             IL  \n",
       "2    WASHINGTON                                20007             DC  \n",
       "3   JERSEY CITY          HUDSON                07302             NJ  \n",
       "4      NEW YORK        NEW YORK                10036             NY  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1b_data_frame_0 = h1b_data_frame.where(h1b_data_frame['S_NO'] < 5 )\n",
    "h1b_data_frame_0.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Convert required columns to categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h1b_data_frame_1 = convertToCategorical(categorical, h1b_data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep columns that we are going to work with in a new dataframe, we remove the old columns that were converted to categorical since we need only the categorical version of those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CASE_STATUS_C=1.0, TOTAL_WORKERS=u'1', NEW_EMPLOYMENT=u'1', CONTINUED_EMPLOYMENT=u'0', CHANGE_PREVIOUS_EMPLOYMENT=u'0', NEW_CONCURRENT_EMPLOYMENT=u'0', CHANGE_EMPLOYER=u'0', AMENDED_PETITION=u'0', PREVAILING_WAGE=u'59197.0', WORKSITE_STATE_C=4.0, NAICS_CODE_C=35.0, SOC_NAME_C=1.0, H1B_DEPENDENT_C=0.0, AGENT_REPRESENTING_EMPLOYER_C=0.0, EMPLOYER_STATE_C=3.0, EMPLOYER_NAME_C=149.0, SUPPORT_H1B_C=0.0, FULL_TIME_POSITION_C=0.0, JOB_TITLE_C=57382.0),\n",
       " Row(CASE_STATUS_C=1.0, TOTAL_WORKERS=u'1', NEW_EMPLOYMENT=u'1', CONTINUED_EMPLOYMENT=u'0', CHANGE_PREVIOUS_EMPLOYMENT=u'0', NEW_CONCURRENT_EMPLOYMENT=u'0', CHANGE_EMPLOYER=u'0', AMENDED_PETITION=u'0', PREVAILING_WAGE=u'49800.0', WORKSITE_STATE_C=4.0, NAICS_CODE_C=35.0, SOC_NAME_C=10.0, H1B_DEPENDENT_C=0.0, AGENT_REPRESENTING_EMPLOYER_C=0.0, EMPLOYER_STATE_C=3.0, EMPLOYER_NAME_C=4198.0, SUPPORT_H1B_C=0.0, FULL_TIME_POSITION_C=0.0, JOB_TITLE_C=105.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keeps = [x for x in keep if x not in categorical.keys() ] + categorical.values()\n",
    "keeps = target + [x for x in keeps if x not in target]\n",
    "h1b_data_frame_2 = h1b_data_frame_1[keeps]\n",
    "h1b_data_frame_2.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the dataframe to rdd so that we can convert to LabeledPoints which  is required for  modelling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [1.0,1.0,0.0,0.0,0.0,0.0,0.0,59197.0,4.0,35.0,1.0,0.0,0.0,3.0,149.0,0.0,0.0,57382.0]),\n",
       " LabeledPoint(1.0, [1.0,1.0,0.0,0.0,0.0,0.0,0.0,49800.0,4.0,35.0,10.0,0.0,0.0,3.0,4198.0,0.0,0.0,105.0])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1b_rdd = h1b_data_frame_2.rdd\n",
    "h1b_labledPoints = h1b_rdd.map(lambda x : LabeledPoint(x[0],x[1:]))\n",
    "h1b_labledPoints.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
